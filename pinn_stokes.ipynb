{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from scipy.interpolate import make_interp_spline, RegularGridInterpolator\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinn import BasePinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StokesPinn(BasePinn):\n",
    "    def __init__(\n",
    "        self, num_boundary_samples=64, num_interior_samples=512, device=\"cuda\", seed=0\n",
    "    ):\n",
    "        self.num_outputs = 3 # pressure, velx, vely\n",
    "\n",
    "        super().__init__(self.num_outputs, num_boundary_samples, num_interior_samples, device, seed, regularization_param=100.0)\n",
    "\n",
    "        self.num_inflow_samples = num_boundary_samples // 4\n",
    "        self.num_wall_samples = num_boundary_samples // 2\n",
    "        self.num_outflow_samples = num_boundary_samples - self.num_inflow_samples - self.num_wall_samples\n",
    "\n",
    "        self.lambda_u = 10e-3 # 10e-10\n",
    "\n",
    "\n",
    "        #Cached values\n",
    "        self.cached_boundary = self.sample_boundary_points(use_cached=False)\n",
    "\n",
    "\n",
    "    def inflow_solution(self, n_samples):\n",
    "        return torch.ones((n_samples)) * self.p_0\n",
    "\n",
    "    def outflow_solution(self, n_samples):\n",
    "        return torch.ones((n_samples)) * self.p_L\n",
    "\n",
    "    def sample_boundary_points(self, use_cached=False):\n",
    "        \n",
    "        if use_cached and self.cached_boundary is None:\n",
    "            raise RuntimeError(\"No cached boundary points\")\n",
    "\n",
    "        if use_cached:\n",
    "            return self.cached_boundary\n",
    "\n",
    "        inflow = self.sample_inflow_points(self.num_inflow_samples)\n",
    "        walls = self.sample_wall_points(self.num_wall_samples)\n",
    "        outflow = self.sample_outflow_points(self.num_outflow_samples)\n",
    "\n",
    "        return torch.cat([inflow, walls, outflow])\n",
    "\n",
    "\n",
    "    def compute_boundary_error(self, use_cached=False):\n",
    "        inflow = self.sample_inflow_points(self.num_inflow_samples)\n",
    "        walls = self.sample_wall_points(self.num_wall_samples)\n",
    "        outflow = self.sample_outflow_points(self.num_outflow_samples)\n",
    "    \n",
    "        pressure_inflow_pred = self.eval(inflow)[:, 0]\n",
    "        pressure_outflow_pred = self.eval(outflow)[:, 0]\n",
    "        vel_walls_pred = self.eval(walls)[:, 1]\n",
    "    \n",
    "        inflow_err = pressure_inflow_pred - self.inflow_solution(self.num_inflow_samples)\n",
    "        outflow_err = pressure_outflow_pred - self.outflow_solution(self.num_outflow_samples)\n",
    "        vel_err = vel_walls_pred\n",
    "\n",
    "        # print(\"pred\", pressure_inflow_pred)\n",
    "        # print(\"solu\", self.inflow_solution(self.num_inflow_samples))\n",
    "            \n",
    "        return 10e3 * torch.cat([inflow_err, outflow_err, vel_err])\n",
    "\n",
    "        \n",
    "\n",
    "    # Compute error with some input/output pair e.g. on the boundaries or as part of supervised training\n",
    "    def compute_supervised_error(self, points, values):\n",
    "        out = self.eval(points)\n",
    "        # error = out - values\n",
    "        # print(error)\n",
    "        return out - values\n",
    "\n",
    "    # Compute error according to the PDE of the interior\n",
    "    def compute_unsupervised_error(self, points, rho, power_map=None, flow_field=None):\n",
    "        points.requires_grad = True\n",
    "        if flow_field is not None or power_map is not None:\n",
    "            print(\"WARNING: flow field or power map are not used\")\n",
    "\n",
    "        rho = torch.tensor(rho(points.cpu().detach().numpy()), dtype=torch.float32).to(self.device).T\n",
    "\n",
    "        flow = self.eval(points)\n",
    "\n",
    "\n",
    "        pressure = flow[:, 0]\n",
    "        grad_pressure = torch.autograd.grad(pressure.sum(), points, create_graph=True)[0]\n",
    "\n",
    "        u = flow[:, 1:]\n",
    "\n",
    "        grad_u = torch.autograd.grad(u.sum(), points, create_graph=True)[0]\n",
    "\n",
    "        grad_u_x = grad_u[:, 0]\n",
    "        grad_u_y = grad_u[:, 1]\n",
    "\n",
    "        grad_grad_u_x = torch.autograd.grad(grad_u_x.sum(), points, create_graph=True)[0]\n",
    "        grad_grad_u_y = torch.autograd.grad(grad_u_y.sum(), points, create_graph=True)[0]\n",
    "\n",
    "        grad_u_xx = grad_grad_u_x[:, 0]      \n",
    "        grad_u_yy = grad_grad_u_y[:, 1]   \n",
    "\n",
    "        div_eps_u = (torch.concat((torch.sum(grad_grad_u_x, dim=1),torch.sum(grad_grad_u_y, dim =1)))).reshape(-1,2)\n",
    "\n",
    "\n",
    "        alpha_rho = (1 - rho) / (1 + self.q_k * rho) * (self.alpha_s - self.alpha_f) + self.alpha_f\n",
    "        alpha_rho = alpha_rho.reshape((alpha_rho.shape[0], 1))\n",
    "\n",
    "\n",
    "        termA = -grad_pressure\n",
    "        termB = 2.0 / self.Re * div_eps_u \n",
    "        termC = - 1.0 / self.Re * (5.0 * self.L**2 / (2.0 * self.H_t**2) + alpha_rho) * u\n",
    "\n",
    "        # print(\"A\", termA.shape, \"B\", termB.shape, \"C\", termC.shape)\n",
    "\n",
    "        stokes = termA + termB + termC\n",
    "\n",
    "        u_div = grad_u_xx + grad_u_yy\n",
    "        \n",
    "        return torch.cat([stokes[:, 0], stokes[:, 1], u_div], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_x, num_y = 100, 100\n",
    "\n",
    "# u_x = np.loadtxt(\"./formatted_data99/results-99.h5_vel_0.out\").reshape(num_x, num_y)\n",
    "# u_y = np.loadtxt(\"./formatted_data99/results-99.h5_vel_1.out\").reshape(num_x, num_y)\n",
    "# u = np.stack([u_x, u_y], -1)\n",
    "\n",
    "# p_map = np.loadtxt(\"./formatted_data99/powermap.out\").reshape(num_x, num_y)\n",
    "\n",
    "rho = np.loadtxt(\"./formatted_data99/results-99.h5_rho.out\").reshape(num_x, num_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(points_out, value=None, num_x=100, num_y=100):\n",
    "    x = np.arange(0 + 0.5 / num_x, 1.0, 1.0 / num_x)\n",
    "    y = np.arange(0 + 0.5 / num_y, 1.0, 1.0 / num_y)\n",
    "\n",
    "    assert value is not None\n",
    "\n",
    "    \n",
    "    interp = RegularGridInterpolator((x, y), value, bounds_error=False, fill_value=None)\n",
    "\n",
    "    if len(value.shape) == 2:\n",
    "        return interp(points_out).T\n",
    "\n",
    "    if len(value.shape) == 3:\n",
    "        return interp(points_out).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_x, num_y = 100, 100\n",
    "x = np.arange(0 + 0.5 / num_x, 1.0, 1.0 / num_x)\n",
    "y = np.arange(0 + 0.5 / num_y, 1.0, 1.0 / num_y)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "points = np.array([X.flatten(), Y.flatten()]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = interpolate(points, u).T.reshape(num_x, num_y, 2).transpose((1, 0, 2))\n",
    "# print(output.shape)\n",
    "# plt.quiver(x, y, u_x, u_y)\n",
    "# plt.show()\n",
    "# plt.quiver(x, y, output[:, :, 0], output[:, :, 1])\n",
    "# plt.show()\n",
    "\n",
    "plt.pcolormesh(rho)\n",
    "plt.show()\n",
    "plt.pcolormesh(interpolate(points, rho).reshape(num_x, num_y).T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinn = StokesPinn(\n",
    "    num_boundary_samples=64, \n",
    "    num_interior_samples=512, \n",
    "    device=\"cuda\", \n",
    "    seed=0\n",
    ")\n",
    "\n",
    "optimizer_LBFGS = optim.LBFGS(pinn.neural_network.parameters(),\n",
    "                              lr=float(0.5),\n",
    "                              max_iter=30000,\n",
    "                              max_eval=30000,\n",
    "                              history_size=150,\n",
    "                              line_search_fn=\"strong_wolfe\",\n",
    "                              tolerance_change=1.0 * np.finfo(float).eps)\n",
    "\n",
    "\n",
    "optimizer_LBFGS_SHORT = optim.LBFGS(pinn.neural_network.parameters(),\n",
    "                              lr=float(0.5),\n",
    "                              max_iter=1000,\n",
    "                              max_eval=1000,\n",
    "                              history_size=150,\n",
    "                              line_search_fn=\"strong_wolfe\",\n",
    "                              tolerance_change=1.0 * np.finfo(float).eps)\n",
    "\n",
    "optimizer_ADAM = optim.Adam(pinn.neural_network.parameters(),\n",
    "                            lr=float(0.005))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "press = np.loadtxt(\"./formatted_data99/results-99.h5_press_0.out\")\n",
    "u_x = np.loadtxt(\"./formatted_data99/results-99.h5_vel_0.out\")\n",
    "u_y = np.loadtxt(\"./formatted_data99/results-99.h5_vel_0.out\")\n",
    "\n",
    "data_points = torch.tensor(points, dtype=torch.float32).to('cuda')\n",
    "flow_combined = torch.tensor(np.stack([press, u_x, u_y], -1).transpose((1, 0, 2)).reshape(100*100, 3), dtype=torch.float32).to('cuda')\n",
    "\n",
    "training_data = DataLoader(\n",
    "                    TensorDataset(data_points, flow_combined),\n",
    "                    batch_size=100 * 100,\n",
    "                    shuffle=False,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pinn.fit(num_epochs = 1,\n",
    "         optimizer = optimizer_LBFGS_SHORT,\n",
    "         data=training_data,\n",
    "         verbose=True)\n",
    "\n",
    "# hist = [0.0, 1.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.plot(np.arange(1, len(hist) + 1), hist, label=\"Train Loss\")\n",
    "# plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(reference):\n",
    "    \n",
    "    inputs = pinn.sample_domain(10000)\n",
    "    pred = pinn.eval(inputs)\n",
    "\n",
    "    pressure = pred[:, 0].reshape(-1,)\n",
    "    vel_x = pred[:, 1].reshape(-1,)\n",
    "    vel_y = pred[:, 2].reshape(-1,)\n",
    "\n",
    "    # print(pred[:, 0])\n",
    "    # print(\"Press\", pressure)\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 8), dpi=150)\n",
    "\n",
    "\n",
    "    im1 = axs[0].tripcolor(inputs[:, 1].detach().cpu(), inputs[:, 0].detach().cpu(), pressure.detach().cpu(), cmap=\"jet\")\n",
    "    axs[0].set_xlabel(\"x\")\n",
    "    axs[0].set_ylabel(\"y\")\n",
    "    plt.colorbar(im1, ax=axs[0], spacing='proportional')\n",
    "    axs[0].grid(True, which=\"both\", ls=\":\")\n",
    "    axs[0].set_title(\"Pressure\")\n",
    "\n",
    "    im2 = axs[1].pcolormesh(reference[:, :, 0], cmap=\"jet\")\n",
    "    axs[1].set_xlabel(\"x\")\n",
    "    axs[1].set_ylabel(\"y\")\n",
    "    plt.colorbar(im2, ax=axs[1])\n",
    "    axs[1].grid(True, which=\"both\", ls=\":\")\n",
    "    axs[1].set_title(\"Pressure Reference\")\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 8), dpi=150)\n",
    "    im1 = axs[0].tripcolor(inputs[:, 1].detach().cpu(), inputs[:, 0].detach().cpu(), vel_x.detach().cpu(), cmap=\"jet\")\n",
    "    axs[0].set_xlabel(\"x\")\n",
    "    axs[0].set_ylabel(\"y\")\n",
    "    plt.colorbar(im1, ax=axs[0], spacing='proportional')\n",
    "    axs[0].grid(True, which=\"both\", ls=\":\")\n",
    "    axs[0].set_title(\"Velocity x\")\n",
    "\n",
    "    im1 = axs[1].pcolormesh(reference[:, :, 1], cmap=\"jet\")\n",
    "    axs[1].set_xlabel(\"x\")\n",
    "    axs[1].set_ylabel(\"y\")\n",
    "    plt.colorbar(im1, ax=axs[1])\n",
    "    axs[1].grid(True, which=\"both\", ls=\":\")\n",
    "    axs[1].set_title(\"Velocity x ref\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 8), dpi=150)\n",
    "    im1 = axs[0].tripcolor(inputs[:, 1].detach().cpu(), inputs[:, 0].detach().cpu(), vel_y.detach().cpu(), cmap=\"jet\")\n",
    "    axs[0].set_xlabel(\"x\")\n",
    "    axs[0].set_ylabel(\"y\")\n",
    "    plt.colorbar(im1, ax=axs[0], spacing='proportional')\n",
    "    axs[0].grid(True, which=\"both\", ls=\":\")\n",
    "    axs[0].set_title(\"Velocity Y\")\n",
    "\n",
    "    im1 = axs[1].pcolormesh(reference[:, :, 2], cmap=\"jet\")\n",
    "    axs[1].set_xlabel(\"x\")\n",
    "    axs[1].set_ylabel(\"y\")\n",
    "    plt.colorbar(im1, ax=axs[1])\n",
    "    axs[1].grid(True, which=\"both\", ls=\":\")\n",
    "    axs[1].set_title(\"Velocity Y reference\")\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # print(reference.shape)\n",
    "\n",
    "    # print(\"Data stats:\", np.mean(reference[:, :, 0]), \n",
    "    #                      np.std(reference[:, :, 0]), \n",
    "    #                      np.mean(reference[:, :, 1]), \n",
    "    #                      np.std(reference[:, :, 1]),\n",
    "    #                      np.mean(reference[:, :, 1]), \n",
    "    #                      np.std(reference[:, :, 1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(np.stack([press, u_x, u_y], -1).reshape(100, 100, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = np.loadtxt(\"./formatted_data10/results-29.h5_rho.out\").reshape(num_x, num_y)\n",
    "\n",
    "press = np.loadtxt(\"./formatted_data10/results-29.h5_press_0.out\")\n",
    "u_x = np.loadtxt(\"./formatted_data10/results-29.h5_vel_0.out\")\n",
    "u_y = np.loadtxt(\"./formatted_data10/results-29.h5_vel_0.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pinn.fit(num_epochs = 1,\n",
    "         optimizer = optimizer_LBFGS,\n",
    "         rho=partial(interpolate, value=rho),\n",
    "         use_cached_data=False,\n",
    "         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.grid(True, which=\"both\", ls=\":\")\n",
    "plt.plot(np.arange(1, len(hist) + 1), hist, label=\"Train Loss\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(rho)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(np.stack([press, u_x, u_y], -1).reshape(100, 100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
